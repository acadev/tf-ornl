{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os.path\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('num_epochs', 5, 'Number of epochs to run trainer.')\n",
    "flags.DEFINE_integer('batch_size', 4096, 'Batch size.')\n",
    "flags.DEFINE_string('train_dir', '/data', 'Directory with the training data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"tf-records.data\"\n",
    "VAL_FILE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(serialized_example):\n",
    "    \"\"\"\n",
    "    Extracts a `dict` of named features from the serialized `tf.train.Example`\n",
    "    \"\"\"\n",
    "    return tf.parse_single_example(\n",
    "        serialized=serialized_example,\n",
    "        features={\n",
    "            'label': tf.FixedLenFeature([99], dtype=tf.int64),\n",
    "            'input': tf.FixedLenFeature([20,111], dtype=tf.int64),\n",
    "        }\n",
    "    )\n",
    "\n",
    "def deserialize_example(serialized_example):\n",
    "    \"\"\"\n",
    "    Converts a serialized `tf.train.Example` to FP32 Tensors\n",
    "    \"\"\"\n",
    "    features = extract_features(serialized_example)\n",
    "    input = tf.cast(features['input'], tf.float32)\n",
    "    label = tf.cast(features['label'], tf.float32)\n",
    "    return input, label\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    \"\"\"\n",
    "    Read and Deserialize a single `tf.train.Example` from a TFRecord file.\n",
    "    \"\"\"\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    return deserialize_example(serialized_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size=None, num_epochs=None, train=True):\n",
    "    \"\"\"\n",
    "    Read in shuffled `inputs` and `labels` from either train or val files.\n",
    "    \n",
    "    Returns:\n",
    "        `inputs` : [batch_size, 20, 111]\n",
    "        `labels` : [batch_size, 99]\n",
    "    \"\"\"\n",
    "    batch_size = batch_size or 128\n",
    "    num_epochs = num_epochs or 1\n",
    "    \n",
    "    filename = os.path.join(FLAGS.train_dir, TRAIN_FILE if train else VALIDATION_FILE)\n",
    "    \n",
    "    with tf.name_scope('input'):\n",
    "        filename_queue = tf.train.string_input_producer([filename], num_epochs=num_epochs)\n",
    "        input, label = read_and_decode(filename_queue)\n",
    "        inputs, labels = tf.train.shuffle_batch(\n",
    "            [input, label], batch_size=batch_size, num_threads=4,\n",
    "            capacity=3 * batch_size,\n",
    "            # Ensures a minimum amount of shuffling of examples.\n",
    "            min_after_dequeue=batch_size\n",
    "        )\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Reading Input\n",
    "\n",
    "The following code block reads the first batch of input data and print out the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_example_new(seq, label):\n",
    "    x = np.transpose(np.nonzero(seq))\n",
    "    y = np.transpose(np.nonzero(label)).reshape(-1)\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'input_dense_dimensions': tf.train.Feature(int64_list=tf.train.Int64List(value=seq.shape)),\n",
    "        'sparse_index_dimensions': tf.train.Feature(int64_list=tf.train.Int64List(value=x.shape)),\n",
    "        'input': tf.train.Feature(int64_list=tf.train.Int64List(value=x.astype(int).reshape(-1))),\n",
    "        'label': tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
    "        'label_length': tf.train.Feature(int64_list=tf.train.Int64List(value=[len(label)])),\n",
    "    }))\n",
    "\n",
    "def extract_features_new(serialized_example):\n",
    "    \"\"\"\n",
    "    Extracts a `dict` of named features from the serialized `tf.train.Example`\n",
    "    \"\"\"\n",
    "    return tf.parse_single_example(\n",
    "        serialized=serialized_example,\n",
    "        features={\n",
    "            'input_dense_dimensions': tf.FixedLenFeature([2], dtype=tf.int64),\n",
    "            'sparse_index_dimensions': tf.FixedLenFeature([2], dtype=tf.int64),\n",
    "            'input': tf.FixedLenFeature([80], dtype=tf.int64),\n",
    "            'label': tf.FixedLenFeature([1], dtype=tf.int64),\n",
    "            'label_length': tf.FixedLenFeature([1], dtype=tf.int64),\n",
    "        }\n",
    "    )\n",
    "\n",
    "def deserialize_example_new(serialized_example):\n",
    "    \"\"\"\n",
    "    Converts a serialized `tf.train.Example` to FP32 Tensors\n",
    "    \"\"\"\n",
    "    features = extract_features_new(serialized_example)\n",
    "    shape_sparse = tf.cast(features['sparse_index_dimensions'], tf.int32)\n",
    "    indices = tf.reshape(tf.cast(features['input'], tf.int32), shape_sparse)\n",
    "    values = tf.ones([shape_sparse[0]])\n",
    "    shape_dense = tf.cast(features['input_dense_dimensions'], tf.int32)\n",
    "    input = tf.sparse_to_dense(indices, shape_dense, values)\n",
    "    label = tf.one_hot(features['label'][0], 99, on_value=1., off_value=0., dtype=tf.float32)\n",
    "    return input, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_batch(input, label, iteration):\n",
    "    with open(\"data/ornl_{0}\".format(iteration), \"w\") as output:\n",
    "        writer = tf.python_io.TFRecordWriter(output.name)\n",
    "        for _x, _y in itertools.izip(_input, _label):\n",
    "            example = make_example_new(_x, _y)\n",
    "            writer.write(example.SerializeToString())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch limit reached\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "batch_size = 4096\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    input, label = get_batch(batch_size=batch_size, num_epochs=1)\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    local_op = tf.initialize_local_variables()\n",
    "    sess.run(init_op)\n",
    "    sess.run(local_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        \n",
    "        iteration = 0\n",
    "        while not coord.should_stop():\n",
    "            _input, _label = sess.run([input, label])\n",
    "            process_batch(_input, _label, iteration)\n",
    "            iteration = iteration + 1\n",
    "                \n",
    "                #example = make_example_new(_x, _y)\n",
    "                #mock_input = tf.constant(example.SerializeToString(), dtype=tf.string)\n",
    "                #xn, yn = deserialize_example_new(mock_input)\n",
    "                #_xn, _yn = sess.run([xn,yn])\n",
    "                #assert np.array_equal(_x, _xn)\n",
    "                #assert np.array_equal(_y, _yn)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    except tf.errors.OutOfRangeError, e:\n",
    "        print(\"epoch limit reached\")\n",
    "        coord.request_stop(e)\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#_tmp1 = numpy.transpose(numpy.nonzero(_input[0]))\n",
    "        #print(tmp1)\n",
    "        #print(_tmp1.shape)\n",
    "        \n",
    "        #tmp1 = tf.constant(_tmp1)\n",
    "        #values = tf.ones([tmp1.get_shape()[0]])\n",
    "        #s2d = tf.sparse_to_dense(tmp1, (20, 111), values)\n",
    "        #s2d = tf.SparseTensor(indices=tmp1, values=tf.ones([tmp1.get_shape()[0]]), shape=(20,111))\n",
    "        #_s2d = sess.run(s2d)\n",
    "        \n",
    "        #print(_s2d.shape)\n",
    "        #print(_s2d)\n",
    "        \"\"\"\n",
    "        _features, _class = tmp1[0::2], tmp1[1::2]\n",
    "        depth = len(_features)\n",
    "        _features = numpy.transpose(_features)[1]\n",
    "        _class = numpy.transpose(_class)[1][0]\n",
    "        #print(_features, _class)\n",
    "        \n",
    "        # expand class to length of features\n",
    "        _cls = numpy.array(_class, ndmin=len(_features), copy=False)\n",
    "        fv = tf.constant(_features)\n",
    "        cl = tf.constant(_cls)\n",
    "        _i = tf.cast(tf.one_hot(fv, 99, on_value=1, off_value=0, axis=-1, dtype=tf.int32), tf.float32)\n",
    "        _c = tf.cast(tf.one_hot(cl, 12, on_value=1, off_value=0, axis=-1, dtype=tf.int32), tf.float32)\n",
    "        #_z = tf.concat(1,[_i,_c])\n",
    "        _t, _tt = sess.run([_i, _c])\n",
    "        print(_t)\n",
    "        \n",
    "        print(_t.shape)\n",
    "        print(_tt.shape)\n",
    "        \"\"\"\n",
    "        #print(numpy.array_equal(_s2d, _input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input/shuffle_batch:0\", shape=(4, 20, 111), dtype=float32)\n",
      "Tensor(\"input/shuffle_batch:1\", shape=(4, 99), dtype=float32)\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Tensor(\"input/shuffle_batch:0\", shape=(4, 20, 111), dtype=float32)\n",
      "Tensor(\"input/shuffle_batch:1\", shape=(4, 99), dtype=float32)\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    input, label = get_batch(batch_size=1024, num_epochs=1)\n",
    "    #filename = os.path.join(FLAGS.train_dir, TRAIN_FILE if True else VALIDATION_FILE)\n",
    "    #filename_queue = tf.train.string_input_producer([filename], num_epochs=1)\n",
    "    #input, label = read_and_decode(filename_queue)\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    local_op = tf.initialize_local_variables()\n",
    "    sess.run(init_op)\n",
    "    sess.run(local_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    try:\n",
    "        step = 0\n",
    "        while not coord.should_stop():\n",
    "            \n",
    "            _inputs, _labels = sess.run([input, label])\n",
    "            \n",
    "            \n",
    "\n",
    "            # Print an overview fairly often.\n",
    "            if step % 50 == 0:\n",
    "                print(step, loss_value, duration)\n",
    "    \n",
    "            step += 1\n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training for %d epochs, %d steps.' % (10, step))\n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    "\n",
    "with open(\"tf-records.data\", \"w\") as output:\n",
    "    writer = tf.python_io.TFRecordWriter(output.name)\n",
    "    for input, label in itertools.izip(X,y):\n",
    "        writer.write(make_example(input, label).SerializeToString())\n",
    "    writer.close()\n",
    "        \n",
    "    # Wait for threads to finish.\n",
    "    coord.join(threads)\n",
    "    \n",
    "    try:\n",
    "        sess.run([input, label])\n",
    "        print(input)\n",
    "        print(label)\n",
    "        print(label.eval())\n",
    "        sess.run([input, label])\n",
    "        print(input)\n",
    "        print(label)\n",
    "        print(label.eval())\n",
    "    except OutOfRangeError, e:\n",
    "        print(\"out of range\")\n",
    "        coord.request_stop(e)\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the ORNL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.objectives import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn_size = 50\n",
    "seq_length = 20\n",
    "num_vocab = 99\n",
    "num_classes = 12\n",
    "\n",
    "batch_size=2048\n",
    "num_epochs=10\n",
    "\n",
    "with tf.name_scope(\"nn\"):\n",
    "    model = Sequential()\n",
    "    model.add( LSTM(rnn_size, input_shape=(seq_length, num_vocab + num_classes)) )\n",
    "    model.add( Dense(num_vocab) )\n",
    "    model.add( Activation('softmax') )\n",
    "\n",
    "def tower_loss(scope):\n",
    "    \"\"\"\n",
    "    Calculate the total loss for a given tower with its own batch of inputs\n",
    "    \"\"\"\n",
    "    inputs, labels = get_batch(batch_size=batch_size, num_epochs=num_epochs)    \n",
    "    logits = model(inputs)\n",
    "    losses = tf.reduce_mean(categorical_crossentropy(labels, logits))\n",
    "    \n",
    "    #with tf.control_dependencies([loss_averages_op]):\n",
    "    #    total_loss = tf.identity(total_loss)\n",
    "\n",
    "    return losses\n",
    "\n",
    "train_step = tf.train.RMSPropOptimizer(0.0005).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.57692 1.60616993904\n",
      "50 4.57074 0.364095926285\n",
      "100 4.44722 0.364655017853\n",
      "150 3.9249 0.349284887314\n",
      "200 3.65361 0.361363172531\n",
      "250 3.42057 0.352455854416\n",
      "300 3.5263 0.394969940186\n",
      "350 3.59692 0.371726036072\n",
      "400 3.3307 0.389976978302\n",
      "450 3.4354 0.360405921936\n",
      "500 3.21467 0.371031045914\n",
      "550 3.38876 0.421336889267\n",
      "600 3.36976 0.360926866531\n",
      "650 3.22834 0.397493839264\n",
      "700 3.20966 0.378099918365\n",
      "750 3.19034 0.359433889389\n",
      "800 3.16402 0.370951890945\n",
      "850 3.09722 0.356650829315\n",
      "900 3.02577 0.363167047501\n",
      "950 3.09209 0.376534938812\n",
      "1000 3.0116 0.36333489418\n",
      "1050 3.00987 0.369508981705\n",
      "1100 2.83554 0.385227918625\n",
      "1150 2.89974 0.359158039093\n",
      "1200 2.94319 0.354926109314\n",
      "1250 3.06177 0.366718053818\n",
      "1300 2.95086 0.358301877975\n",
      "1350 2.82427 0.357882976532\n",
      "1400 2.735 0.389733076096\n",
      "1450 2.75951 0.374725103378\n",
      "1500 2.91092 0.366447925568\n",
      "1550 2.77232 0.362352132797\n",
      "1600 2.87021 0.363610029221\n",
      "1650 2.62245 0.393249988556\n",
      "1700 2.6608 0.414990901947\n",
      "1750 2.79919 0.362905025482\n",
      "1800 2.71966 0.407791137695\n",
      "1850 2.64667 0.356989145279\n",
      "1900 2.63035 0.366691112518\n",
      "1950 2.65967 0.352986097336\n",
      "2000 2.53905 0.363172054291\n",
      "2050 2.67979 0.361598014832\n",
      "2100 2.69508 0.362828016281\n",
      "2150 2.61507 0.352944135666\n",
      "2200 2.50609 0.372437953949\n",
      "2250 2.61836 0.412609100342\n",
      "2300 2.56113 0.373600006104\n",
      "2350 2.55163 0.381804943085\n",
      "2400 2.54814 0.383821964264\n",
      "2450 2.54675 0.405558824539\n",
      "2500 2.40662 0.369700908661\n",
      "2550 2.39703 0.359000921249\n",
      "2600 2.61819 0.411030054092\n",
      "2650 2.42075 0.35778093338\n",
      "2700 2.48002 0.368009090424\n",
      "2750 2.40654 0.357694149017\n",
      "2800 2.39182 0.367623090744\n",
      "2850 2.40415 0.370936155319\n",
      "2900 2.4175 0.408123016357\n",
      "2950 2.43652 0.366526842117\n",
      "3000 2.40385 0.369451999664\n",
      "3050 2.33638 0.432415962219\n",
      "3100 2.51187 0.358418941498\n",
      "3150 2.43907 0.371781826019\n",
      "3200 2.33608 0.406512022018\n",
      "3250 2.44365 0.352333784103\n",
      "3300 2.37424 0.368386983871\n",
      "3350 2.26666 0.364344120026\n",
      "3400 2.34833 0.350447893143\n",
      "3450 2.31836 0.399127006531\n",
      "3500 2.34331 0.368943214417\n",
      "3550 2.34815 0.40686583519\n",
      "3600 2.34416 0.388267040253\n",
      "3650 2.33962 0.35998916626\n",
      "3700 2.26007 0.356905937195\n",
      "3750 2.30603 0.408178091049\n",
      "3800 2.39486 0.405663967133\n",
      "3850 2.4109 0.366680145264\n",
      "3900 2.28029 0.361839056015\n",
      "3950 2.16851 0.368947029114\n",
      "4000 2.26716 0.364238977432\n",
      "4050 2.15456 0.368541002274\n",
      "4100 2.2564 0.363194942474\n",
      "4150 2.12081 0.365314006805\n",
      "4200 2.24632 0.358455896378\n",
      "4250 2.05092 0.364595174789\n",
      "4300 2.24002 0.380883932114\n",
      "4350 2.06744 0.407763004303\n",
      "4400 2.2162 0.382751226425\n",
      "4450 2.20448 0.358994960785\n",
      "4500 2.26441 0.36307311058\n",
      "4550 2.28272 0.394623041153\n",
      "4600 2.20567 0.388005018234\n",
      "4650 2.02394 0.362607955933\n",
      "4700 2.01644 0.357876777649\n",
      "4750 2.25791 0.411388158798\n",
      "4800 2.25249 0.408488035202\n",
      "4850 2.21878 0.379804134369\n",
      "4900 2.34795 0.37219786644\n",
      "4950 2.14678 0.414573907852\n",
      "5000 2.16716 0.387945890427\n",
      "5050 2.17768 0.364804029465\n",
      "5100 2.23621 0.384420871735\n",
      "5150 2.2479 0.374558925629\n",
      "5200 2.15928 0.362916946411\n",
      "5250 2.19033 0.369307994843\n",
      "5300 2.15859 0.405550003052\n",
      "5350 2.17558 0.418127059937\n",
      "5400 2.12742 0.352824926376\n",
      "5450 2.1358 0.357147932053\n",
      "5500 2.18809 0.424520969391\n",
      "5550 2.0968 0.354098081589\n",
      "5600 2.0863 0.364548921585\n",
      "5650 2.01736 0.357154846191\n",
      "5700 2.07379 0.361103057861\n",
      "5750 2.0122 0.353573083878\n",
      "5800 2.05053 0.357172966003\n",
      "5850 1.96252 0.365770101547\n",
      "5900 2.09363 0.402770042419\n",
      "5950 1.98964 0.365231990814\n",
      "6000 2.0824 0.387075185776\n",
      "6050 2.05724 0.385839939117\n",
      "6100 2.17878 0.355783939362\n",
      "6150 1.96752 0.36695599556\n",
      "6200 1.97029 0.363133192062\n",
      "6250 2.04321 0.367281913757\n",
      "6300 2.15292 0.402975082397\n",
      "6350 2.10499 0.362521886826\n",
      "6400 2.20272 0.385247945786\n",
      "6450 1.99509 0.355844974518\n",
      "6500 2.09705 0.358550071716\n",
      "6550 2.21952 0.418869972229\n",
      "6600 2.03343 0.367894172668\n",
      "6650 2.03012 0.609856843948\n",
      "6700 2.27281 0.38835477829\n",
      "6750 1.98073 0.412981033325\n",
      "6800 2.05789 0.404740095139\n",
      "6850 1.94219 0.37372803688\n",
      "6900 1.95601 0.368278026581\n",
      "6950 2.19809 0.406481981277\n",
      "7000 2.14077 0.367630958557\n",
      "7050 2.02139 0.418664932251\n",
      "7100 1.94505 0.407913923264\n",
      "7150 1.88933 0.3716340065\n",
      "7200 1.88372 0.366129159927\n",
      "7250 2.14617 0.411287069321\n",
      "7300 1.8744 0.370990037918\n",
      "7350 1.89245 0.36648106575\n",
      "7400 1.9119 0.37094783783\n",
      "7450 1.7007 0.431236028671\n",
      "7500 2.00051 0.366194009781\n",
      "7550 1.98761 0.364674806595\n",
      "7600 1.98874 0.380693912506\n",
      "7650 1.84139 0.420058012009\n",
      "7700 1.96384 0.378895044327\n",
      "7750 2.07572 0.417541027069\n",
      "7800 2.0755 0.417895078659\n",
      "7850 1.87645 0.426096916199\n",
      "7900 1.92907 0.400203943253\n",
      "7950 1.89711 0.383051872253\n",
      "8000 2.03398 0.410216093063\n",
      "8050 2.0088 0.395815849304\n",
      "8100 1.89659 0.375037908554\n",
      "8150 1.78242 0.382450819016\n",
      "8200 1.94195 0.366416931152\n",
      "8250 1.83572 0.380073785782\n",
      "8300 1.88395 0.425488948822\n",
      "8350 1.95977 0.377038002014\n",
      "8400 1.8563 0.389139890671\n",
      "8450 1.86683 0.41977596283\n",
      "8500 2.02478 0.371688127518\n",
      "8550 1.85508 0.383840084076\n",
      "8600 1.78892 0.376311063766\n",
      "8650 1.90272 0.355933904648\n",
      "8700 1.80727 0.411041975021\n",
      "8750 2.21247 0.409332036972\n",
      "8800 1.83401 0.417130947113\n",
      "8850 1.9191 0.408310890198\n",
      "8900 1.94399 0.367527961731\n",
      "8950 1.65552 0.385403871536\n",
      "9000 1.95767 0.366898059845\n",
      "9050 1.93676 0.356783866882\n",
      "9100 1.78335 0.365554094315\n",
      "9150 1.72253 0.376374006271\n",
      "9200 2.03816 0.371912002563\n",
      "9250 2.02087 0.418015956879\n",
      "9300 2.01167 0.429134130478\n",
      "9350 1.92996 0.429109096527\n",
      "9400 1.68284 0.359013080597\n",
      "9450 1.82645 0.389759778976\n",
      "9500 1.96718 0.409595012665\n",
      "9550 2.05451 0.401306867599\n",
      "9600 1.85578 0.373383998871\n",
      "9650 1.8212 0.411458969116\n",
      "9700 1.70637 0.358859062195\n",
      "9750 1.8427 0.375404119492\n",
      "9800 1.87598 0.391444206238\n",
      "9850 1.91142 0.427793979645\n",
      "9900 1.97075 0.37326002121\n",
      "9950 1.81786 0.3966319561\n",
      "10000 1.68181 0.417006015778\n",
      "10050 1.89659 0.397697925568\n",
      "10100 1.70683 0.366708040237\n",
      "10150 1.74563 0.409169197083\n",
      "10200 1.67272 0.41063117981\n",
      "10250 2.08479 0.403563022614\n",
      "10300 1.80084 0.408421039581\n",
      "10350 1.68057 0.372432947159\n",
      "10400 1.65014 0.409563064575\n",
      "10450 1.70136 0.377188920975\n",
      "10500 1.79706 0.350517988205\n",
      "10550 1.90373 0.385569095612\n",
      "10600 1.961 0.415704965591\n",
      "10650 1.81329 0.420035839081\n",
      "10700 1.82724 0.366807937622\n",
      "10750 1.95565 0.370308876038\n",
      "10800 1.8751 0.416014909744\n",
      "10850 2.01802 0.379304885864\n",
      "10900 1.73776 0.365009784698\n",
      "10950 1.80058 0.384011030197\n",
      "11000 2.12948 0.424366950989\n",
      "11050 1.85064 0.362747192383\n",
      "11100 1.6754 0.362400054932\n",
      "11150 1.86351 0.429316997528\n",
      "11200 1.79884 0.361968994141\n",
      "11250 1.85736 0.407676935196\n",
      "11300 1.73378 0.3799700737\n",
      "11350 1.77923 0.406585931778\n",
      "11400 1.94348 0.424533128738\n",
      "11450 1.58333 0.361963033676\n",
      "11500 1.61905 0.4209420681\n",
      "11550 1.86785 0.402093887329\n",
      "11600 1.72701 0.416006088257\n",
      "11650 1.75929 0.367526054382\n",
      "11700 1.76329 0.421951055527\n",
      "11750 1.99172 0.420339107513\n",
      "11800 1.79822 0.420157909393\n",
      "11850 1.68099 0.382256031036\n",
      "11900 1.68876 0.400403022766\n",
      "11950 1.72315 0.395884037018\n",
      "12000 1.89509 0.430001974106\n",
      "12050 1.99874 0.413738012314\n",
      "12100 1.85428 0.35772395134\n",
      "12150 1.72597 0.377163171768\n",
      "12200 1.79902 0.367993116379\n",
      "12250 1.72605 0.396250009537\n",
      "12300 1.68975 0.417500972748\n",
      "12350 1.81568 0.424592018127\n",
      "12400 1.7197 0.397476911545\n",
      "12450 1.61014 0.370866060257\n",
      "12500 2.05019 0.385422945023\n",
      "12550 1.76994 0.404132843018\n",
      "12600 1.75123 0.373728990555\n",
      "12650 1.72674 0.421777963638\n",
      "12700 1.66492 0.3807721138\n",
      "12750 1.77418 0.400020837784\n",
      "12800 1.91489 0.428780078888\n",
      "12850 1.78468 0.410137176514\n",
      "12900 1.88271 0.36762714386\n",
      "12950 1.52405 0.392686128616\n",
      "13000 1.69736 0.350164890289\n",
      "13050 1.68486 0.40923500061\n",
      "13100 1.78946 0.411460876465\n",
      "13150 1.96053 0.395612955093\n",
      "13200 1.67142 0.431027889252\n",
      "13250 1.78743 0.410273075104\n",
      "13300 1.68819 0.39389705658\n",
      "13350 1.67282 0.359236955643\n",
      "13400 1.57105 0.417645931244\n",
      "13450 1.49471 0.411952018738\n",
      "13500 1.72927 0.376411914825\n",
      "13550 1.83091 0.395784854889\n",
      "13600 1.69858 0.4210729599\n",
      "13650 1.75226 0.392409086227\n",
      "13700 1.63039 0.373656988144\n",
      "13750 1.78688 0.402262926102\n",
      "13800 1.74511 0.375086069107\n",
      "13850 1.77227 0.37202501297\n",
      "13900 1.9822 0.407378911972\n",
      "13950 1.58187 0.380158901215\n",
      "14000 1.86235 0.39156293869\n",
      "14050 1.68363 0.409461975098\n",
      "14100 1.71046 0.377794027328\n",
      "14150 1.60492 0.412541866302\n",
      "14200 1.75961 0.364511966705\n",
      "14250 1.79094 0.367891073227\n",
      "14300 1.65888 0.393824100494\n",
      "14350 1.54366 0.398532867432\n",
      "14400 1.70509 0.369034051895\n",
      "14450 1.56039 0.379675149918\n",
      "14500 1.76129 0.401779174805\n",
      "14550 2.08181 0.380373001099\n",
      "14600 1.70424 0.41478395462\n",
      "14650 1.7975 0.363180160522\n",
      "14700 1.59792 0.380103111267\n",
      "14750 1.69368 0.422529935837\n",
      "14800 1.61463 0.408404111862\n",
      "14850 1.6486 0.390964031219\n",
      "14900 1.56814 0.396460056305\n",
      "14950 1.47222 0.380265951157\n",
      "Done training for 10 epochs, 14975 steps.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    keras.backend.set_session(sess)\n",
    "    \n",
    "    init_op = tf.group(tf.initialize_all_variables(),\n",
    "                       tf.initialize_local_variables())\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    try:\n",
    "        step = 0\n",
    "        while not coord.should_stop():\n",
    "            start_time = time.time()\n",
    "            \n",
    "            _, loss_value = sess.run([train_step, loss]) #, feed_dict={\n",
    "            #        inputs: batch[0].eval(),\n",
    "            #        labels: batch[1].eval()\n",
    "            #})\n",
    "        \n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            # Print an overview fairly often.\n",
    "            if step % 50 == 0:\n",
    "                print(step, loss_value, duration)\n",
    "    \n",
    "            step += 1\n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training for %d epochs, %d steps.' % (10, step))\n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    "\n",
    "    # Wait for threads to finish.\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
